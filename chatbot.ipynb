{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e2e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Enhanced Perplexity Chatbot\n",
      "==================================================\n",
      "üîë API Key Setup\n",
      "--------------------\n",
      "ü§ñ Enhanced Perplexity Chatbot Started!\n",
      "Type 'help' for commands, 'quit' to exit\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Searching and thinking...\n",
      "\n",
      "ü§ñ Assistant (sonar-pro): Thanks for checking in! As an AI, I don't experience emotions, but I'm here to help you with any questions or information you need. If you meant \"Hi How Are You\" in reference to something specific‚Äîsuch as the famous Daniel Johnston album[4], the mental health project inspired by it[1], or a recent song, let me know and I can provide details.\n",
      "\n",
      "üìö Sources:\n",
      "  1. Hi, How Are You Project... - https://www.hihowareyou.org\n",
      "  2. Daniel Johnston - Hi, How Are You (Full Album, 1983)... - https://www.youtube.com/watch?v=AW2cmIIomac\n",
      "  3. Kenya Grace - Hey, Hi, How are you? (Official Lyric Video)... - https://www.youtube.com/watch?v=j7asUTbtNWc\n",
      "\n",
      "üìä Tokens: 83 | Total: 83\n",
      "\n",
      "üîç Searching and thinking...\n",
      "\n",
      "ü§ñ Assistant (sonar-pro): Before making a chatbot, you need a structured plan that covers defining its purpose, selecting the right deployment channels, choosing suitable technologies, designing the conversation flow, training and testing the bot, and planning for launch and ongoing monitoring[1][2][3][4].\n",
      "\n",
      "Key steps and plans to check before building a chatbot include:\n",
      "\n",
      "1. **Define the Purpose and Objectives**\n",
      "   - Clearly identify what you want the chatbot to achieve (e.g., customer service, sales support, lead generation)[1][4].\n",
      "   - Determine the audience and the problems the chatbot will solve[3].\n",
      "   - Set measurable goals for chatbot performance (e.g., reducing response times, improving user satisfaction)[4].\n",
      "\n",
      "2. **Select Deployment Channels**\n",
      "   - Choose where the bot will operate: website, mobile app, messaging platforms like WhatsApp, Facebook Messenger, Slack, etc.[1][2].\n",
      "   - Match channels to audience preferences and ensure easy integration.\n",
      "\n",
      "3. **Choose the Technology Stack**\n",
      "   - Decide between custom development or using no-code/low-code platforms[1][3].\n",
      "   - Select appropriate frameworks, programming languages (such as Python), and AI/NLP libraries (like NLTK, SpaCy, TensorFlow, or commercial platforms like Dialogflow, IBM Watson)[1][3].\n",
      "   - Consider infrastructure: cloud-based for scalability, or on-premise for data control[1].\n",
      "\n",
      "4. **Design Conversation Flow**\n",
      "   - Map typical user journeys, possible questions, and the chatbot‚Äôs responses[2][3].\n",
      "   - Design the chatbot‚Äôs personality and voice for a consistent user experience[3].\n",
      "   - Use flowcharts or storyboards to lay out conversation logic[2].\n",
      "\n",
      "5. **Build and Train the Chatbot**\n",
      "   - Develop or configure the bot using chosen tools[1].\n",
      "   - Train the AI using real-life conversations and datasets, continuously improving its performance based on feedback and data[2][3].\n",
      "\n",
      "6. **Testing and Quality Assurance**\n",
      "   - Thoroughly test the chatbot with various user inputs and scenarios[2][3].\n",
      "   - Evaluate for both usability and technical reliability using automated and manual tests.\n",
      "\n",
      "7. **Launch and Monitor**\n",
      "   - Deploy the chatbot and integrate it with business systems[3].\n",
      "   - Set up security, analytics, and ongoing monitoring to track usage, identify issues, and measure KPIs (e.g., successful query resolution)[3].\n",
      "   - Plan for iterative improvements based on user feedback and performance data.\n",
      "\n",
      "By systematically addressing these areas, you ensure your chatbot aligns with business goals, provides value to users, and operates reliably across its target channels[1][2][3][4].\n",
      "\n",
      "üìö Sources:\n",
      "  1. Chatbot Development Guide for Business Owners in 2025 - Mobi... - https://mobidev.biz/blog/chatbot-development-guide\n",
      "  2. AI Chatbot Development: Detailed Step-by-Step Guide... - https://www.designveloper.com/guide/ai-chatbot-development/\n",
      "  3. Chatbot Development Guide 2024: Roadmap & Strategies - Quidg... - https://quidget.ai/blog/ai-automation/chatbot-development-guide-2024-roadmap-and-strategies/\n",
      "\n",
      "üìä Tokens: 640 | Total: 723\n",
      "\n",
      "üëã Goodbye! Thanks for chatting!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# api_key is set in main() or from environment variable\n",
    "\n",
    "class EnhancedPerplexityChatbot:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        self.conversation_history = []\n",
    "        self.available_models = [\n",
    "            \"sonar-pro\",\n",
    "            \"sonar\",\n",
    "            \"sonar-reasoning\",\n",
    "            \"sonar-deep-research\"\n",
    "        ]\n",
    "        self.current_model = \"sonar-pro\"\n",
    "        self.total_tokens_used = 0\n",
    "\n",
    "    def send_message(self, message, model=None, search_options=None):\n",
    "        \"\"\"Send a message to Perplexity API with advanced options\"\"\"\n",
    "\n",
    "        if model is None:\n",
    "            model = self.current_model\n",
    "\n",
    "        # Add user message to history\n",
    "        user_message = {\"role\": \"user\", \"content\": message}\n",
    "        self.conversation_history.append(user_message)\n",
    "\n",
    "        # Prepare the payload with advanced options\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": self.conversation_history,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        # Add search options if provided\n",
    "        if search_options:\n",
    "            payload.update(search_options)\n",
    "\n",
    "        try:\n",
    "            # Make API request with retry logic\n",
    "            response = self._make_request_with_retry(payload)\n",
    "\n",
    "            if response:\n",
    "                assistant_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                # Add assistant response to history\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "                # Update token usage\n",
    "                usage = response.get(\"usage\", {})\n",
    "                self.total_tokens_used += usage.get(\"total_tokens\", 0)\n",
    "\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"message\": assistant_message,\n",
    "                    \"usage\": usage,\n",
    "                    \"search_results\": response.get(\"search_results\", []),\n",
    "                    \"model_used\": model\n",
    "                }\n",
    "            else:\n",
    "                return {\"success\": False, \"error\": \"Failed to get response after retries\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "    def _make_request_with_retry(self, payload, max_retries=3):\n",
    "        \"\"\"Make API request with exponential backoff retry\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.post(self.base_url, headers=self.headers, json=payload)\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except requests.exceptions.RateLimitError:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = (2 ** attempt) + 1\n",
    "                    print(f\"Rate limited. Waiting {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    raise\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Request failed (attempt {attempt + 1}). Retrying...\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    raise e\n",
    "        return None\n",
    "\n",
    "    def change_model(self, model_name):\n",
    "        \"\"\"Change the current AI model\"\"\"\n",
    "        if model_name in self.available_models:\n",
    "            self.current_model = model_name\n",
    "            print(f\"‚úÖ Model changed to: {model_name}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Invalid model. Available models: {', '.join(self.available_models)}\")\n",
    "\n",
    "    def search_with_filters(self, query, domain=None, published_after=None):\n",
    "        \"\"\"Search with domain and date filters\"\"\"\n",
    "        search_options = {}\n",
    "\n",
    "        if domain:\n",
    "            search_options[\"search_domain\"] = domain\n",
    "\n",
    "        if published_after:\n",
    "            search_options[\"web_search_options\"] = {\"published_after\": published_after}\n",
    "\n",
    "        return self.send_message(query, search_options=search_options)\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"üßπ Conversation history cleared!\")\n",
    "\n",
    "    def show_stats(self):\n",
    "        \"\"\"Display comprehensive statistics\"\"\"\n",
    "        print(f\"\\nüìä Chatbot Statistics\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Current Model: {self.current_model}\")\n",
    "        print(f\"Messages in History: {len(self.conversation_history)}\")\n",
    "        print(f\"Total Tokens Used: {self.total_tokens_used}\")\n",
    "        print(f\"Available Models: {', '.join(self.available_models)}\")\n",
    "\n",
    "    def export_conversation(self, filename=None):\n",
    "        \"\"\"Export conversation to JSON file\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"conversation_{timestamp}.json\"\n",
    "\n",
    "        conversation_data = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"model_used\": self.current_model,\n",
    "            \"total_tokens\": self.total_tokens_used,\n",
    "            \"conversation\": self.conversation_history\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(conversation_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"üíæ Conversation exported to: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to export conversation: {str(e)}\")\n",
    "\n",
    "    def show_help(self):\n",
    "        \"\"\"Display help information\"\"\"\n",
    "        help_text = \"\"\"\n",
    "ü§ñ Perplexity Chatbot Commands:\n",
    "\n",
    "Basic Commands:\n",
    "  quit          - Exit the chatbot\n",
    "  clear         - Clear conversation history\n",
    "  stats         - Show usage statistics\n",
    "  help          - Show this help message\n",
    "  export        - Export conversation to JSON\n",
    "\n",
    "Model Commands:\n",
    "  model <name>  - Change AI model (sonar-pro, sonar, sonar-reasoning, sonar-deep-research)\n",
    "  models        - List available models\n",
    "\n",
    "Advanced Search:\n",
    "  domain <domain> <query>  - Search specific domain (e.g., \"domain wikipedia.org tell me about AI\")\n",
    "  recent <query>           - Search for recent information (last 30 days)\n",
    "\n",
    "Examples:\n",
    "  > What's the weather like today?\n",
    "  > model sonar-reasoning\n",
    "  > domain sec.gov What are Tesla's latest earnings?\n",
    "  > recent AI developments in 2024\n",
    "        \"\"\"\n",
    "        print(help_text)\n",
    "\n",
    "    def chat_loop(self):\n",
    "        \"\"\"Enhanced chat loop with commands\"\"\"\n",
    "        print(\"ü§ñ Enhanced Perplexity Chatbot Started!\")\n",
    "        print(\"Type 'help' for commands, 'quit' to exit\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nüë§ You: \").strip()\n",
    "\n",
    "                if not user_input:\n",
    "                    continue\n",
    "\n",
    "                # Handle commands\n",
    "                if user_input.lower() == 'quit':\n",
    "                    print(\"\\nüëã Goodbye! Thanks for chatting!\")\n",
    "                    break\n",
    "                elif user_input.lower() == 'clear':\n",
    "                    self.clear_history()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'stats':\n",
    "                    self.show_stats()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'help':\n",
    "                    self.show_help()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'export':\n",
    "                    self.export_conversation()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'models':\n",
    "                    print(f\"Available models: {', '.join(self.available_models)}\")\n",
    "                    print(f\"Current model: {self.current_model}\")\n",
    "                    continue\n",
    "                elif user_input.lower().startswith('model '):\n",
    "                    model_name = user_input[6:].strip()\n",
    "                    self.change_model(model_name)\n",
    "                    continue\n",
    "                elif user_input.lower().startswith('domain '):\n",
    "                    parts = user_input[7:].split(' ', 1)\n",
    "                    if len(parts) == 2:\n",
    "                        domain, query = parts\n",
    "                        print(f\"\\nüîç Searching {domain} for: {query}\")\n",
    "                        result = self.search_with_filters(query, domain=domain)\n",
    "                    else:\n",
    "                        print(\"Usage: domain <domain> <query>\")\n",
    "                        continue\n",
    "                elif user_input.lower().startswith('recent '):\n",
    "                    query = user_input[7:].strip()\n",
    "                    from datetime import datetime, timedelta\n",
    "                    thirty_days_ago = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "                    print(f\"\\nüîç Searching for recent info about: {query}\")\n",
    "                    result = self.search_with_filters(query, published_after=thirty_days_ago)\n",
    "                else:\n",
    "                    # Regular chat message\n",
    "                    print(\"\\nüîç Searching and thinking...\")\n",
    "                    result = self.send_message(user_input)\n",
    "\n",
    "                # Display results\n",
    "                if 'result' in locals() and result[\"success\"]:\n",
    "                    print(f\"\\nü§ñ Assistant ({result['model_used']}): {result['message']}\")\n",
    "\n",
    "                    # Show sources\n",
    "                    if result.get(\"search_results\"):\n",
    "                        print(\"\\nüìö Sources:\")\n",
    "                        for i, source in enumerate(result[\"search_results\"][:3], 1):\n",
    "                            title = source.get('title', 'Unknown')[:60]\n",
    "                            url = source.get('url', 'No URL')\n",
    "                            print(f\"  {i}. {title}... - {url}\")\n",
    "\n",
    "                    # Show usage\n",
    "                    if result.get(\"usage\"):\n",
    "                        usage = result[\"usage\"]\n",
    "                        tokens = usage.get('total_tokens', 'N/A')\n",
    "                        print(f\"\\nüìä Tokens: {tokens} | Total: {self.total_tokens_used}\")\n",
    "\n",
    "                elif 'result' in locals():\n",
    "                    print(f\"\\n‚ùå Error: {result['error']}\")\n",
    "\n",
    "                # Clear result variable\n",
    "                if 'result' in locals():\n",
    "                    del result\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nüëã Goodbye! Thanks for chatting!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Unexpected error: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ Enhanced Perplexity Chatbot\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Get API key\n",
    "    api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"üîë API Key Setup\")\n",
    "        print(\"-\" * 20)\n",
    "        api_key = input(\"Enter your Perplexity API key: \").strip()\n",
    "\n",
    "        if not api_key:\n",
    "            print(\"‚ùå API key is required!\")\n",
    "            return\n",
    "\n",
    "    # Create and start enhanced chatbot\n",
    "    chatbot = EnhancedPerplexityChatbot(api_key)\n",
    "    chatbot.chat_loop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21600fb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m client = OpenAI(api_key=\u001b[33m\"\u001b[39m\u001b[33msk-proj-usGusn75Wh9t3C3Qf_rroig5dd10FKInG7SMTD_UrcjB9ws2taM3Ih86B-l7EWYMwNZC3jYl9cT3BlbkFJkhPNza3WsfrasCUZRSXYITMZAPPHnXsSycK0-6oSt95b2z8fRD2i4XExgTf9n0BVWA8C-zKxUA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create a response using a valid OpenAI model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a short bedtime story about a unicorn.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1150\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1147\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1148\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1149\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the client with your API key\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# Create a response using a valid OpenAI model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short bedtime story about a unicorn.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
